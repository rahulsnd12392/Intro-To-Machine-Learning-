{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "canadian-philadelphia"
   },
   "source": [
    "#### For this Assignment you have been given a data which is a subset of a bigger dataset which was collected by Buffalo Tax department. It contains information regarding the various properties in Buffalo.\n",
    "\n",
    "Number of Instances: 92508\n",
    "\n",
    "Number of Attributes: 16 (including the target variable)\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "| Column Name                | Description                                                                                                                                      | Type        |\n",
    "|----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|-------------|\n",
    "| TOTAL VALUE                | The combined assessed value of the land and improvements on the parcel                                                                           | Number      |\n",
    "| FRONT                      | The width of the front of property (in feet)                                                                                                     | Number      |\n",
    "| DEPTH                      | The depth of the property (in feet)                                                                                                              | Number      |\n",
    "| PROPERTY CLASS             | Property Type Classification Codes describe the primary use of each parcel of real property on the assessment roll                               | Number      |\n",
    "| LAND VALUE                 | The assessed value of the land                                                                                                                   | Number      |\n",
    "| SALE PRICE                 | The price that the parcel of real property was last sold for                                                                                     | Number      |\n",
    "| YEAR BUILT                 | The year the primary building on the parcel was built                                                                                            | Number      |\n",
    "| TOTAL LIVING AREA          | The amount of living space (in square feet)                                                                                                      | Number      |\n",
    "| OVERALL CONDITION          | A grade of the condition of the property                                                                                                         | Number      |\n",
    "| BUILDING STYLE             | A code for the style of building                                                                                                                 | Number      |\n",
    "| HEAT TYPE                  | The type of heating system in the building (only applicable to residential properties)                                                           | Number      |\n",
    "| BASEMENT TYPE              | The type of basement on the property (only applicable to residential properties)                                                                 | Number      |\n",
    "| # OF STORIES               | The number of floors/Stories in the property                                                                                                     | Number      |\n",
    "| # OF FIREPLACES            | The number of fireplaces in a dwelling (only applicable to residential properties)                                                               | Number      |\n",
    "| # OF BEDS                  | The number of beds in a dwelling (only applicable to residential properties)                                                                     | Number      |\n",
    "| # OF BATHS                 | The number of baths in a dwelling (only applicable to residential properties)                                                                    | Number      |\n",
    "| # OF KITCHENS              | The number of kitchens in a dwelling (only applicable to residential properties)                                                                 | Number      |\n",
    "\n",
    "\n",
    "\n",
    "There are no missing Attribute Values.\n",
    "\n",
    "Your task is to implement a Linear Regression Model to predict the TOTAL VALUE of a property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "planned-perry"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "traditional-tissue"
   },
   "source": [
    "#### STEP 1 - Load Data (Already Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "measured-report"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "preliminary-wireless"
   },
   "outputs": [],
   "source": [
    "y = np.asarray(df['TOTAL VALUE'] )\n",
    "y = y.reshape(y.shape[0],1)\n",
    "feature_cols = df.columns.to_list()\n",
    "feature_cols.remove('TOTAL VALUE')\n",
    "x = np.asarray(df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92508\n",
      "64755\n",
      "18501\n",
      "9250\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(int(len(x)*0.7))\n",
    "print(int(len(x)*0.2))\n",
    "print(int(len(x)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "available-picnic"
   },
   "source": [
    "Variable **y** contains the total values of the property\n",
    "\n",
    "Variable **x** contains the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twelve-skill"
   },
   "source": [
    "#### STEP 2 - Split the Data into training and testing and validation split ( 70% Training, 20% Testing and 10% validation) ( Hint: you can use the sklearn library for this step only) ( 5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "downtown-antarctica"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64755, 18502, 9251, 64755, 18502, 9251)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=1/3, random_state = 42)\n",
    "X_train.shape[0], X_test.shape[0], X_val.shape[0],y_train.shape[0], y_test.shape[0], y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "theoretical-allergy"
   },
   "source": [
    "#### STEP 3 - Scale Data Using Min Max Scaler (10 Points)\n",
    "For each feature scaled value can be calculated using $  x_{scaled} = \\frac{x - min(x)}{max(x) - min(x)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "civilian-lounge"
   },
   "outputs": [],
   "source": [
    "#STEP 3\n",
    "X_scaled     = (X_train - np.min(X_train))/ (np.max(X_train) - np.min(X_train))\n",
    "X_Test_scaled = (X_test - np.min(X_test))/ (np.max(X_test) - np.min(X_test))\n",
    "X_Val_scaled  = (X_val - np.min(X_val))/ (np.max(X_val) - np.min(X_val))\n",
    "y_scaled     = (y_train - np.min(y_train))/ (np.max(y_train) - np.min(y_train))\n",
    "y_Test_scaled = (y_test - np.min(y_test))/ (np.max(y_test) - np.min(y_test))\n",
    "y_Val_scaled  = (y_val - np.min(y_val))/ (np.max(y_val) - np.min(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prostate-disney"
   },
   "source": [
    "#### STEP 4 - Initialize values for the weights, No. of Epochs and Learning Rate (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "absolute-associate"
   },
   "outputs": [],
   "source": [
    "#STEP 4\n",
    "theta = np.random.rand(15,1)\n",
    "learning_rate = 0.001   \n",
    "epochs = 100\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moved-parking"
   },
   "source": [
    "#### STEP 5 - Train Linear Regression Model (40 Points)\n",
    " 5.1 Start a Loop For each Epoch\n",
    " \n",
    " 5.2 Find the predicted value using $ y(x,w) = w_0 + w_1x $ for the training and validation splits (10 Points)\n",
    " \n",
    " 5.3 Find the Loss using Mean Squared Error for the training and validation splits and store in a list (10 Points)\n",
    " \n",
    " 5.4 Calculate the Gradients (15 Points)\n",
    " \n",
    " 5.5 Update the weights using the gradients (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "alleged-diary"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09538785235732072, -1.1627539881414717, -7.024141322473927)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# def gradient_descent(X, y, theta, epochs):\n",
    "#     b0 = 1\n",
    "#     b1 = np.ones((15,1))\n",
    "#     mse_list   = []\n",
    "#     pred_list  = []\n",
    "   \n",
    "#     for i in range(epochs):\n",
    "#         error = (b0 + X.dot(b1)) - y\n",
    "#         b0 = theta -theta * (error.sum() / len(y) )\n",
    "#         b1 = theta -theta * (X.T.dot(error) / len(y))\n",
    "#         mse_list.append(1/(2*len(y))*np.dot(error.T,error))\n",
    "#         pred_list.append(X*theta)\n",
    "        \n",
    "#     return mse_list, pred_list\n",
    "\n",
    "\n",
    "# mse_list_train, pred_list_train = gradient_descent(X_scaled, y_scaled, theta=0.001, epochs=15)\n",
    "# mse_list_test, pred_list_test = gradient_descent(X_test, y_test, theta=0.001, epochs=15)\n",
    "# mse_list_val, pred_list_val = gradient_descent(X_val, y_val, theta=0.001, epochs=15)\n",
    "# mse_list_train\n",
    "# mse_list_test\n",
    "# mse_list_val\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_scaled, y_scaled)\n",
    "train_score = regressor.score(X_scaled, y_scaled)\n",
    "test_score = regressor.score(X_Test_scaled, y_Test_scaled)\n",
    "valid_score = regressor.score(X_Val_scaled, y_Val_scaled)\n",
    "\n",
    "train_score, test_score, valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = make_pipeline(SGDRegressor(max_iter=1000, alpha=0.001))\n",
    "reg.fit(X_train, y_train.ravel())\n",
    "y_pred_train = reg.predict(X_train)\n",
    "\n",
    "reg_test = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, alpha=0.001))\n",
    "reg_test.fit(X_test, y_test.ravel())\n",
    "y_pred_test = reg.predict(X_test)\n",
    "\n",
    "reg_val = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, alpha=0.001))\n",
    "reg_val.fit(X_val, y_val.ravel())\n",
    "y_pred_val = reg.predict(X_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuzzy-prairie"
   },
   "source": [
    "#### STEP 6 - Evaluate the Model ( 25 Points)\n",
    "6.1 Plot a graph of the Training and Validation Loss wrt epochs (10 Points)\n",
    "\n",
    "6.2 Find the R2 Score of the trained model for the Train, Test and Validation splits (15 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 15 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-705bb5d01638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1276\u001b[0m            \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m         \"\"\"\n\u001b[1;32m-> 1278\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m     def _fit_regressor(self, X, y, alpha, C, loss, learning_rate,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1262\u001b[1;33m         scores = safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[0;32m   1263\u001b[0m                                  dense_output=True) + self.intercept_\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 15 is different from 1)"
     ]
    }
   ],
   "source": [
    "reg.score(y_train,y_pred_train), reg_test.score(y_test,y_pred_test), reg_val.score(y_val,y_val_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "outstanding-jewel"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
